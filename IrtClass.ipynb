{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class RangeError(Exception):\n",
    "    \"\"\"Eccezione per input fuori dal range\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class EvalError(Exception):\n",
    "    \"\"\"Eccezione per metofo evalDf senza una tabella di probabilità \"\"\"\n",
    "    pass\n",
    "\n",
    "class Irt:\n",
    "    \"\"\"Classe creata per applicare algoritmi di Item Response Theory ad oggetti che rappresentano le prove d'esame,\n",
    "       i quali hanno una riga per studente e le colonne rappresentano gli item su cui applicare le funzioni.\n",
    "       Le intersezioni rappresentano il voto preso da uno studente per quell'esercizio.\"\"\"\n",
    "    \n",
    "    __minVal    = 0\n",
    "    __maxVal    = 10\n",
    "    __flagValue = True # flag per impedire alzare una eccezione in evalDf se ancora non è stato eseguito un metodo di PLN\n",
    "        \n",
    "    def __init__(self, path):        \n",
    "        \"\"\"Il costruttore prende come parametro il path del file csv da analizzare.\"\"\"        \n",
    "        self.__df     = pd.read_csv(path, index_col = 0) # rendo la prima colonna l'indice della tabella\n",
    "        self.numItems = len(self.__df.columns) # salvo il numero di items    \n",
    "        self.__dfProb = pd.DataFrame(columns=self.__df.columns, index=self.__df.index) # per semplicità creo la databella di probabilità che verrà riempita dalle funzioni PLN   \n",
    "     \n",
    "    def changeInterval(self, min, max):\n",
    "        \"\"\"Modifica l'intervallo di valori delle difficoltà e dei discriminanti di default sono (0,10), estremi compresi.\"\"\"\n",
    "        self.__minVal = min\n",
    "        self.__maxVal = max        \n",
    "    \n",
    "    def __getNumInput(self,msg):\n",
    "        \"\"\"Prende valore in input assicurandosi che sia intero e compreso nell'intervallo fissato per difficotà e discriminati.\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                n = float(input(msg))\n",
    "                if n < self.__minVal or n > self.__maxVal:\n",
    "                    raise RangeError\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"L'input non è un numero!\")\n",
    "            except RangeError:\n",
    "                print(\"L'input non è compreso nell'intervallo (\", self.__minVal, \",\" , self.__maxVal, \")!\")\n",
    "        return n \n",
    "        \n",
    "    def __getProbInput(self,msg):\n",
    "        \"\"\"Prende valore in input assicurandosi che sia una percentuale compresa tra 0% e 100%.\"\"\"\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                n = float(input(msg))\n",
    "                if n < 0 or n > 100:\n",
    "                    raise RangeError\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"L'input non è un numero!\")\n",
    "            except RangeError:\n",
    "                print(\"L'input non è una probabilità compresa tra 0 e 100!\")\n",
    "        return n      \n",
    "       \n",
    "    def __getDiff(self, n):\n",
    "        \"\"\"Metodo usato per ottenere la lista di difficoltà degli esercizi.\"\"\"\n",
    "        \n",
    "        lsDiff = pd.DataFrame(columns = self.__df.columns , index = [\"Difficulty\"])        \n",
    "        print(\"Insersci la difficoltà per i seguenti item, essa deve essere compresa nell'intervallo (\", self.__minVal, \",\" , self.__maxVal, \") : \\n\")\n",
    "        for columns in lsDiff:\n",
    "            lsDiff.loc[\"Difficulty\",columns] = self.__getNumInput(columns + \": \")\n",
    "        return lsDiff \n",
    "\n",
    "    def __getDiscrim(self, n):\n",
    "        \"\"\"Metodo usato per ottenere la lista di discriminanti degli esercizi.\"\"\"       \n",
    "        \n",
    "        lsDiscrim = pd.DataFrame(columns = self.__df.columns , index = [\"Discriminant\"])        \n",
    "        print(\"Insersci il discriminante per i seguenti item, essa deve essere compresa nell'intervallo (\", self.__minVal, \",\" , self.__maxVal, \") : \\n\")\n",
    "        for columns in lsDiscrim:\n",
    "            lsDiscrim.loc[\"Discriminant\",columns] = self.__getNumInput(columns + \": \")\n",
    "        return lsDiscrim\n",
    "\n",
    "    def __getGuess(self, n):\n",
    "        \"\"\"Metodo usato per ottenere la lista di probabilità di indovinare esercizi\"\"\"    \n",
    "        \n",
    "        lsGuess = pd.DataFrame(columns = self.__df.columns , index = [\"Guess\"])        \n",
    "        print(\"Insersci la difficoltà per i seguenti item, essa deve essere compresa tra 0 e 100: \\n\")\n",
    "        for columns in lsGuess:\n",
    "            lsGuess.loc[\"Guess\",columns] = self.__getProbInput(columns + \": \")/100\n",
    "        return lsGuess  \n",
    "    \n",
    "    def __estimateAbility(self, lsDiff):\n",
    "        \"\"\"Metodo usato per fornire una stima delle abilità degli studenti\"\"\"   \n",
    "        \n",
    "        lsAb         = pd.DataFrame(index = self.__df.index , columns = [\"Ability\"])\n",
    "        difficulties = lsDiff.loc[\"Difficulty\"]        \n",
    "        \n",
    "        for index, row in self.__df.iterrows():\n",
    "            ability                   = (row*difficulties).sum()/difficulties.sum() # stimo mediante media ponderata\n",
    "            lsAb.loc[index,\"Ability\"] = round(ability, 2)\n",
    "        return lsAb      \n",
    "    \n",
    "    def pl1(self):\n",
    "        \"\"\"Applica il modello PL1 dell'Item Response Theory, esso usa solo il parametro delle difficoltà\"\"\" \n",
    "        \n",
    "        self.__flagValue = False\n",
    "        lsDiff = self.__getDiff(self.numItems)\n",
    "        lsAb   = self.__estimateAbility(lsDiff)\n",
    "\n",
    "        for index, row in self.__dfProb.iterrows():\n",
    "            for columns in self.__dfProb:\n",
    "                ability    = lsAb.loc  [index,\"Ability\"]\n",
    "                difficulty = lsDiff.loc[\"Difficulty\",columns]\n",
    "                res        = (math.exp(ability - difficulty)) / (1 + math.exp(ability - difficulty))\n",
    "                self.__dfProb.loc[index, columns] = str(round(res * 100 , 2)) + \"%\"\n",
    "        return self.__dfProb\n",
    "\n",
    "    def pl2(self):\n",
    "        \"\"\"Applica il modello PL2 dell'Item Response Theory, esso usa le difficoltà ed i discriminanti\"\"\"  \n",
    "        \n",
    "        self.__flagValue = False        \n",
    "        lsDiff    = self.__getDiff(self.numItems)\n",
    "        lsAb      = self.__estimateAbility(lsDiff)\n",
    "        print()\n",
    "        lsDiscrim = self.__getDiscrim(self.numItems)\n",
    "\n",
    "        for index, row in self.__dfProb.iterrows():\n",
    "            for columns in self.__dfProb:\n",
    "                ability      = lsAb.loc     [index,\"Ability\"]\n",
    "                difficulty   = lsDiff.loc   [\"Difficulty\",columns]      \n",
    "                discriminant = lsDiscrim.loc[\"Discriminant\",columns]\n",
    "                res          = (math.exp(discriminant * (ability - difficulty))) / (1 + math.exp(discriminant * (ability - difficulty)))\n",
    "                self.__dfProb.loc[index, columns] = str(round(res * 100 , 2)) + \"%\"\n",
    "        return self.__dfProb\n",
    "\n",
    "    def pl3(self):\n",
    "        \"\"\"Applica il modello PL3 dell'Item Response Theory, esso usa le difficoltà, discriminanti e \n",
    "        le probabilità di indovinare gli esercizi.\"\"\"              \n",
    "        \n",
    "        self.__flagValue = False        \n",
    "        lsDiff    = self.__getDiff(self.numItems)\n",
    "        lsAb      = self.__estimateAbility(lsDiff)\n",
    "        print()\n",
    "        lsDiscrim = self.__getDiscrim(self.numItems)\n",
    "        print()\n",
    "        lsGuess   = self.__getGuess(self.numItems)\n",
    "        \n",
    "        for index, row in self.__dfProb.iterrows():\n",
    "            for columns in self.__dfProb:\n",
    "                ability      = lsAb.loc     [index,\"Ability\"]\n",
    "                difficulty   = lsDiff.loc   [\"Difficulty\",columns]      \n",
    "                discriminant = lsDiscrim.loc[\"Discriminant\",columns]            \n",
    "                guessProb    = lsGuess.loc  [\"Guess\",columns]\n",
    "                res          = guessProb + (1 - guessProb) * (math.exp(discriminant * (ability - difficulty))) / (1 + math.exp(discriminant * (ability - difficulty)))\n",
    "                self.__dfProb.loc[index, columns] = str(round(res * 100 , 2)) + \"%\"\n",
    "        return self.__dfProb    \n",
    "  \n",
    "    def evalDf(self):\n",
    "        \"\"\"Questo metodo ha lo scopo di stabilire quanto sono corretti i parametri stabiliti per il calcolo delle probabilità \n",
    "        dell'ultimo modello utilizzato, prima di applicarlo è necessario usare un algoritmo PLN per l'oggetto in questione.\"\"\"\n",
    "        \n",
    "        if self.__flagValue:\n",
    "            raise EvalError(\"Prima di eseguire la valutazione è necessario applicare un metodo di PLN!\")\n",
    "        dfCorrect = pd.DataFrame(columns=self.__df.columns, index=[\"Precise\"])\n",
    "        dfC       = self.__df.fillna(0)\n",
    "        for columns in self.__df:\n",
    "            dfDiff = np.array([])          \n",
    "            for index, row in self.__df.iterrows():\n",
    "                vote = dfC.loc[index, columns]\n",
    "                votePerc     = ( vote * 100)/self.__maxVal \n",
    "                plProbString = self.__dfProb.loc[index, columns]\n",
    "                plProbFloat  = float(plProbString[:-1])\n",
    "                dfDiff       = np.append(dfDiff, abs(votePerc - plProbFloat)) # differenza tra la probabilità e la percentuale del voto rispetto al massimo\n",
    "            dfCorrect.loc[\"Precise\", columns] = str(100 - round(dfDiff.mean(), 2)) + \"%\"\n",
    "        return dfCorrect        \n",
    "    \n",
    "    def getDf(self):\n",
    "        \"\"\"Restituisce la tabella relativa al file csv utilizzato.\"\"\"\n",
    "        return self.__df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insersci la difficoltà per i seguenti item, essa deve essere compresa nell'intervallo ( 0 , 10 ) : \n",
      "\n",
      "Esercizio 1: 5\n",
      "Esercizio 2: 6\n",
      "Esercizio 3: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Esercizio 1</th>\n",
       "      <th>Esercizio 2</th>\n",
       "      <th>Esercizio 3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Studente</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Marco</th>\n",
       "      <td>95.52%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>74.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simone</th>\n",
       "      <td>69.64%</td>\n",
       "      <td>45.76%</td>\n",
       "      <td>23.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Davide</th>\n",
       "      <td>25.73%</td>\n",
       "      <td>11.3%</td>\n",
       "      <td>4.48%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Esercizio 1 Esercizio 2 Esercizio 3\n",
       "Studente                                    \n",
       "Marco         95.52%       88.7%      74.27%\n",
       "Simone        69.64%      45.76%      23.69%\n",
       "Davide        25.73%       11.3%       4.48%"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Irt(\"testcsv.csv\")\n",
    "test.pl1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Esercizio 1</th>\n",
       "      <th>Esercizio 2</th>\n",
       "      <th>Esercizio 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precise</th>\n",
       "      <td>63.04%</td>\n",
       "      <td>69.45%</td>\n",
       "      <td>57.48%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Esercizio 1 Esercizio 2 Esercizio 3\n",
       "Precise      63.04%      69.45%      57.48%"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.evalDf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
