{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "class Irt:\n",
    "    \"\"\"Classe creata per applicare algoritmi di Item Response Theory ad oggetti che rappresentano le prove d'esame,\n",
    "       i quali hanno una riga per studente e le colonne rappresentano gli item su cui applicare le funzioni.\"\"\"\n",
    "    \n",
    "    __minVote = 0\n",
    "    __maxVote = 10\n",
    "    \n",
    "    def __init__(self, path):        \n",
    "        \"\"\"Il costruttore prende come parametro il path del file csv da analizzare.\"\"\"        \n",
    "        self.__df = pd.read_csv(path, index_col = 0) # rendo la prima colonna l'indice della tabella\n",
    "        self.numItems = len(self.__df.columns) # salvo il numero di items    \n",
    "        \n",
    "    def __getVoteInput(self,msg):\n",
    "        \"\"\"Prendo voto in input assicurandomi che sia intero e compreso nell'intervallo\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                vote = int(input(msg))\n",
    "                if vote not in range(self.__minVote,self.__maxVote + 1):\n",
    "                    raise ValueError\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Input non intero o non compreso nel range (\", self.__minVote, \",\" , self.__maxVote, \")\")\n",
    "        return vote\n",
    "       \n",
    "    def __getDiff(self, n):\n",
    "        \"\"\"Metodo usato per ottenere la lista di difficoltà degli esercizi\"\"\"\n",
    "        \n",
    "        lsDiff = pd.DataFrame(columns = self.__df.columns , index = [\"Difficulty\"])\n",
    "        print(\"Insersci la difficoltà per i seguenti item: \\n\")\n",
    "        for columns in lsDiff:\n",
    "            lsDiff.loc[\"Difficulty\",columns] = self.__getVoteInput(columns + \": \")\n",
    "        return lsDiff \n",
    "\n",
    "    def __getDiscrim(self, n):\n",
    "        \"\"\"Metodo usato per ottenere la lista di discriminanti degli esercizi\"\"\"        \n",
    "        \n",
    "        lsDiscrim = pd.DataFrame(columns = self.__df.columns , index = [\"Discriminant\"])\n",
    "        print(\"Insersci i discriminanti per i seguenti item: \\n\")\n",
    "        for columns in lsDiscrim:\n",
    "            lsDiscrim.loc[\"Discriminant\",columns] = self.__getVoteInput(columns + \": \")\n",
    "        return lsDiscrim\n",
    "\n",
    "    def __getGuess(self, n):\n",
    "        \"\"\"Metodo usato per ottenere la lista di probabilità di indovinare esercizi\"\"\"    \n",
    "        \n",
    "        lsGuess = pd.DataFrame(columns = self.__df.columns , index = [\"Guess\"])\n",
    "        print(\"Insersci le probabilità di indovinare i seguenti item: \\n\")\n",
    "        for columns in lsGuess:\n",
    "            lsGuess.loc[\"Guess\",columns] = float(input(columns + \": \"))\n",
    "        return lsGuess  \n",
    "    \n",
    "    def __estimateAbility(self, lsDiff):\n",
    "        \"\"\"Metodo usato per fornire una stima delle abilità degli studenti tramite una media ponderata\"\"\"   \n",
    "        \n",
    "        lsAb = pd.DataFrame(index = self.__df.index , columns = [\"Ability\"])\n",
    "        for index, row in self.__df.iterrows():\n",
    "            ability = (row*(lsDiff.loc[\"Difficulty\"])).sum()/lsDiff.loc[\"Difficulty\"].sum()\n",
    "            lsAb.loc[index,\"Ability\"] = round(ability, 2)\n",
    "        return lsAb      \n",
    "    \n",
    "    def pl1(self):\n",
    "        \"\"\"Metodo usato per applicare il modello PL1 dell'Item Response Theory, esso usa solo il parametro delle difficoltà\"\"\" \n",
    "        \n",
    "        lsDiff = self.__getDiff(self.numItems)\n",
    "        lsAb   = self.__estimateAbility(lsDiff)\n",
    "        dfProb = pd.DataFrame(columns=self.__df.columns, index=self.__df.index)\n",
    "        for index, row in dfProb.iterrows():\n",
    "            for columns in dfProb:\n",
    "                ability    = lsAb.loc  [index,\"Ability\"]\n",
    "                difficulty = lsDiff.loc[\"Difficulty\",columns]\n",
    "                res = (math.exp(ability - difficulty)) / (1 + math.exp(ability - difficulty))\n",
    "                dfProb.loc[index, columns] = str(round(res * 100 , 2)) + \"%\"\n",
    "        return dfProb\n",
    "\n",
    "    def pl2(self):\n",
    "        \"\"\"Metodo usato per applicare il modello PL1 dell'Item Response Theory, esso usa le difficoltà ed i discriminanti\"\"\"  \n",
    "        \n",
    "        lsDiff    = self.__getDiff(self.numItems)\n",
    "        lsAb      = self.__estimateAbility(lsDiff)\n",
    "        print()\n",
    "        lsDiscrim = self.__getDiscrim(self.numItems)\n",
    "        dfProb = pd.DataFrame(columns=self.__df.columns, index=self.__df.index)\n",
    "        for index, row in dfProb.iterrows():\n",
    "            for columns in dfProb:\n",
    "                ability      = lsAb.loc     [index,\"Ability\"]\n",
    "                difficulty   = lsDiff.loc   [\"Difficulty\",columns]      \n",
    "                discriminant = lsDiscrim.loc[\"Discriminant\",columns]\n",
    "                res = (math.exp(discriminant * (ability - difficulty))) / (1 + math.exp(discriminant * (ability - difficulty)))\n",
    "                dfProb.loc[index, columns] = str(round(res * 100 , 2)) + \"%\"\n",
    "        return dfProb\n",
    "\n",
    "    def pl3(self):\n",
    "        \"\"\"Metodo usato per applicare il modello PL1 dell'Item Response Theory, esso usa le difficoltà, discriminanti e \n",
    "        le probabilità di indovinare gli esercizi\"\"\"        \n",
    "        \n",
    "        lsDiff    = self.__getDiff(self.numItems)\n",
    "        lsAb      = self.__estimateAbility(lsDiff)\n",
    "        print()\n",
    "        lsDiscrim = self.__getDiscrim(self.numItems)\n",
    "        print()\n",
    "        lsGuess   = self.__getGuess(self.numItems)\n",
    "        dfProb    = pd.DataFrame(columns=self.__df.columns, index=self.__df.index)\n",
    "        \n",
    "        for index, row in dfProb.iterrows():\n",
    "            for columns in dfProb:\n",
    "                ability      = lsAb.loc     [index,\"Ability\"]\n",
    "                difficulty   = lsDiff.loc   [\"Difficulty\",columns]      \n",
    "                discriminant = lsDiscrim.loc[\"Discriminant\",columns]            \n",
    "                guessProb    = lsGuess.loc  [\"Guess\",columns]\n",
    "                res = guessProb + (1 - guessProb) * (math.exp(discriminant * (ability - difficulty))) / (1 + math.exp(discriminant * (ability - difficulty)))\n",
    "                dfProb.loc[index, columns] = str(round(res * 100 , 2)) + \"%\"\n",
    "        return dfProb    \n",
    "    \n",
    "    def getDf(self):\n",
    "        \"\"\"Restituisce il la tabella relativa al file csv utilizzato\"\"\"\n",
    "        return self.__df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insersci la difficoltà per i seguenti item: \n",
      "\n",
      "Esercizio1: 5\n",
      "Esercizio2: 6\n",
      "Esercizio3: 7\n",
      "\n",
      "Insersci i discriminanti per i seguenti item: \n",
      "\n",
      "Esercizio1: 1\n",
      "Esercizio2: 1\n",
      "Esercizio3: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Esercizio1</th>\n",
       "      <th>Esercizio2</th>\n",
       "      <th>Esercizio3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Studente</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Marco</th>\n",
       "      <td>81.76%</td>\n",
       "      <td>62.25%</td>\n",
       "      <td>37.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simone</th>\n",
       "      <td>54.24%</td>\n",
       "      <td>30.36%</td>\n",
       "      <td>13.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Davide</th>\n",
       "      <td>86.18%</td>\n",
       "      <td>69.64%</td>\n",
       "      <td>45.76%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Esercizio1 Esercizio2 Esercizio3\n",
       "Studente                                 \n",
       "Marco        81.76%     62.25%     37.75%\n",
       "Simone       54.24%     30.36%     13.82%\n",
       "Davide       86.18%     69.64%     45.76%"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Irt(\"testcsv.csv\")\n",
    "test.pl2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
